{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from icalendar import *\n",
    "from datetime import date, datetime, timedelta\n",
    "from __future__ import print_function\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import pickle\n",
    "import csv\n",
    "import pandas\n",
    "from pandas.io import sql\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pytz\n",
    "import calendar_parser as cp \n",
    "# for calendar_parser, I downloaded the Python file created for this package\n",
    "# https://github.com/oblique63/Python-GoogleCalendarParser/blob/master/calendar_parser.py\n",
    "# and saved it in the working directory with my Python file (Jupyter Notebook file). \n",
    "# In calendar_parser.py, their function _fix_timezone is very crucial for my code to \n",
    "# display the correct local time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Connection with MySQL (optional approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "User =     # MySQL Username\n",
    "Password = # MySQL password\n",
    "Host =     # MySQL host\n",
    "cnx = mysql.connector.connect(user=User, password=Password, host=Host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Approach / Code modified from MySQL Connector web page\n",
    "DB_NAME = \"CalDb\"\n",
    "\n",
    "# 1) Creates database if it doesn't already exist\n",
    "# 2) Then connects to the database\n",
    "def create_database(cursor):\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            \"CREATE DATABASE {} DEFAULT CHARACTER SET 'utf8'\".format(DB_NAME))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Failed creating database: {}\".format(err))\n",
    "        exit(1)\n",
    "\n",
    "try:\n",
    "    cnx.database = DB_NAME    \n",
    "except mysql.connector.Error as err:\n",
    "    if err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        create_database(cursor)\n",
    "        cnx.database = DB_NAME\n",
    "    else:\n",
    "        print(err)\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create table specifications\n",
    "TABLES = {}\n",
    "TABLES['eBike'] = (\n",
    "    \"CREATE TABLE IF NOT EXISTS `eBike` (\"\n",
    "    \"  `eBikeName` varchar(10),\"\n",
    "    \"  `Organizer` varchar(100),\"\n",
    "    \"  `Created` datetime NOT NULL,\"\n",
    "    \"  `Start` datetime NOT NULL,\"\n",
    "    \"  `End` datetime NOT NULL\"\n",
    "    \") ENGINE=InnoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table eBike: OK\n"
     ]
    }
   ],
   "source": [
    "# If table does not already exist, this code will create it based on specifications\n",
    "for name, ddl in TABLES.iteritems():\n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(name), end='')\n",
    "        cursor.execute(ddl)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(\"already exists.\")\n",
    "        else:\n",
    "            print(err.msg)\n",
    "    else:\n",
    "        print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain current count from each calendar to read in and add additional entries only\n",
    "cursor.execute(\"SELECT COUNT(*) FROM eBike WHERE eBikeName = 'Gold'\")\n",
    "GoldExistingCount = cursor.fetchall()\n",
    "\n",
    "cursor.execute(\"SELECT COUNT(*) FROM eBike WHERE eBikeName = 'Blue'\")\n",
    "BlueExistingCount = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#print(GoldExistingCount[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Calendar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare lists\n",
    "eBikeName = []\n",
    "Organizer = []\n",
    "DTcreated = []\n",
    "DTstart = []\n",
    "DTend = []\n",
    "Counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open first e-bike calendar, appends data, then repeats for second calendar. \n",
    "# A future modification I am working on is to bring this into one loop such that \n",
    "# as many calendars as desired for a specific table can be read in from one folder. \n",
    "#\n",
    "# Additionally, I plan to look into potential for using the .ics url to read in\n",
    "# calendar data so that the file does not need to be updated each time this code\n",
    "# is run for analysis of calendar data. \n",
    "b = open('Gold.ics','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cal = Calendar.from_ical(b.read())\n",
    "\n",
    "timezones = cal.walk('VTIMEZONE')\n",
    "\n",
    "for k in cal.walk():\n",
    "    if k.name == \"VEVENT\":\n",
    "        Counter = Counter + 1\n",
    "        if Counter > GoldExistingCount[0][0]:\n",
    "            eBikeName.append('Gold')\n",
    "            Organizer.append( re.sub(r'mailto:', \"\", str(k.get('ORGANIZER') ) ) )\n",
    "            DTcreated.append( cp._fix_timezone( k.decoded('CREATED'), pytz.timezone(timezones[0]['TZID']) ) )\n",
    "            DTstart.append( cp._fix_timezone( k.decoded('DTSTART'), pytz.timezone(timezones[0]['TZID']) ) )\n",
    "            DTend.append( cp._fix_timezone( k.decoded('DTEND'), pytz.timezone(timezones[0]['TZID']) ) )\n",
    "\n",
    "b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Resetting 'Counter' to 0 and opening next calendar...\n",
    "Counter = 0\n",
    "b = open('Blue.ics','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cal = Calendar.from_ical(b.read())\n",
    "\n",
    "timezones = cal.walk('VTIMEZONE')\n",
    "\n",
    "for k in cal.walk():\n",
    "    if k.name == \"VEVENT\":\n",
    "        Counter = Counter + 1\n",
    "        if Counter > BlueExistingCount[0][0]:\n",
    "            eBikeName.append('Blue')\n",
    "            Organizer.append( re.sub(r'mailto:', \"\", str(k.get('ORGANIZER') ) ) )\n",
    "            DTcreated.append( cp._fix_timezone( k.decoded('CREATED'), pytz.timezone(timezones[0]['TZID']) ) )\n",
    "            DTstart.append( cp._fix_timezone( k.decoded('DTSTART'), pytz.timezone(timezones[0]['TZID']) ) )\n",
    "            DTend.append( cp._fix_timezone( k.decoded('DTEND'), pytz.timezone(timezones[0]['TZID']) ) )\n",
    "\n",
    "b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now that calendar data is fully read in, create a list with data in a format for \n",
    "# entering into the MySQL database. \n",
    "# \n",
    "# At this point, if the MySQL Connector component is not desired, other approaches  \n",
    "# include creating a Pandas dataframe or something else.\n",
    "# For reference, a Pandas dataframe could be created with the following command: \n",
    "# df = pandas.DataFrame({'ORGANIZER' : Organizer,'CREATED' : DTcreated, 'DTSTART' : DTstart,'DTEND': DTend})\n",
    "eBikeData = []\n",
    "for i in range(len(DTcreated)):\n",
    "    eBikeData.append((eBikeName[i], Organizer[i], DTcreated[i], DTstart[i], DTend[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL Connection to Push Out and Read In Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert calendar data into MySQL table eBike\n",
    "cursor.executemany(\"INSERT INTO eBike (eBikeName, Organizer, Created, Start, End) VALUES (%s, %s, %s, %s, %s)\", \n",
    "                   eBikeData)\n",
    "cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find emails associated with reservations created at latest 7 days ago\n",
    "cursor.execute(\"SELECT Organizer, Start FROM eBike WHERE DATEDIFF(Start, CURDATE()) >= 7\")\n",
    "WeeklyEmail = cursor.fetchall()\n",
    "print(WeeklyEmail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find total e-bike rides by user\n",
    "cursor.execute(\"SELECT Organizer, COUNT(*) AS Total_Rides FROM eBike GROUP BY Organizer ORDER BY Total_Rides DESC;\")\n",
    "TotalRides_by_User = cursor.fetchall()\n",
    "print(TotalRides_by_User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desired Features (planned future improvements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features to add within the next week: Total Trips by Reservation Time, Total Trips by Weekday, \n",
    "# Average and Maximum Hours by Weekday, Average and Maximum Utilization by Weekday, \n",
    "# Find how far in advance reservations are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate reports from SQL query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SINGLE LOOP READ-IN FEATURE\n",
    "\n",
    "# Enter desired directory where .ics files are contained\n",
    "#path = '/Users/dmeroux/Documents/Calendar_Data_Extraction_V1.0'\n",
    "#for infile in glob.glob( os.path.join(path, '*.ics') ):\n",
    "#    b = open(infile,'rb')\n",
    "#    cal = Calendar.from_ical(b.read())\n",
    "#    for k in cal.walk():\n",
    "#        if k.name == \"VEVENT\": \n",
    "#            if str(type(k.decoded('DTSTART'))) == \"<class 'datetime.datetime'>\":\n",
    "#                Organizer.append( re.sub(r'mailto:', \"\", str(k.get('ORGANIZER') ) ) )   # email address of organizer\n",
    "#                DTcreated.append( datetime.timestamp(k.decoded('CREATED') ) ) # reservation created date\n",
    "#                DTstart.append( datetime.timestamp(k.decoded('DTSTART') ) )  # reservation start date\n",
    "#                DTend.append( datetime.timestamp(k.decoded('DTEND') ) )     # reservation end date\n",
    "#    b.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# URL FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option to work with Pandas Dataframe (this code runs properly)\n",
    "################################### ISSUE TRANSFERRING 'SUMMARY' INTO MYSQL \"TOO LONG\"\n",
    "#df = pandas.DataFrame({'ORGANIZER' : Organizer,'CREATED' : DTcreated, 'DTSTART' : DTstart,'DTEND': DTend})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add use case with PySpark\n",
    "# FOR PYSPARK APPROACH, TRY CONNECTING TO MYSQL https://www.supergloo.com/fieldnotes/spark-sql-mysql-python-example-jdbc/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
